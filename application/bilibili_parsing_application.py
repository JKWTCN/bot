import json
import logging
import os
import re
import traceback
import concurrent.futures
from threading import Lock
import asyncio

import requests
from data.application.group_message_application import GroupMessageApplication
from data.application.application_info import ApplicationInfo
from data.enumerates import ApplicationCostType
from data.message.group_message_info import GroupMessageInfo
from function.say import SayRaw, ReplySay, ReplySayImage, ReplySayTextImage
from function.GroupConfig import get_config
import random
import uuid
import cv2
import subprocess
import numpy as np

from function.group_setting import LoadGroupSetting, DumpGroupSetting
from tools.tools import HasAllKeyWords


def extract_single_frame(args):
    """æå–å•ä¸ªå¸§çš„å‡½æ•°ï¼Œç”¨äºå¤šçº¿ç¨‹"""
    input_video, output_folder, time_point, frame_index, lock = args

    output_path = os.path.join(output_folder, f"frame_{frame_index+1:03d}.jpg")

    cmd = [
        "ffmpeg",
        "-y",  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
        "-ss",
        str(time_point),  # è·³è½¬åˆ°æŒ‡å®šæ—¶é—´
        "-i",
        input_video,
        "-vframes",
        "1",  # åªæå–ä¸€å¸§
        "-vf",
        "scale=-1:720",  # ç¼©æ”¾é«˜åº¦ä¸º720ä¿æŒå®½é«˜æ¯”
        "-q:v",
        "2",  # é«˜è´¨é‡
        "-f",
        "image2",
        output_path,
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)

    # ä½¿ç”¨é”æ¥å®‰å…¨åœ°æ‰“å°è¿›åº¦ä¿¡æ¯
    with lock:
        if result.returncode != 0:
            print(f"æå–ç¬¬{frame_index+1}å¸§æ—¶å‡ºé”™: {result.stderr}")
            return False
        else:
            print(f"å·²æå–ç¬¬{frame_index+1}å¸§ (æ—¶é—´ç‚¹: {time_point:.2f}s)")
            return True


def extract_frames(input_video, output_folder, num_frames=16, max_workers=4):
    """ä½¿ç”¨FFmpegå¤šçº¿ç¨‹ä»è§†é¢‘ä¸­å‡åŒ€æå–æŒ‡å®šæ•°é‡çš„å¸§"""
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # è·å–è§†é¢‘æ—¶é•¿
    try:
        # ä½¿ç”¨FFprobeè·å–è§†é¢‘æ—¶é•¿
        probe_cmd = [
            "ffprobe",
            "-v",
            "quiet",
            "-select_streams",
            "v:0",
            "-show_entries",
            "format=duration",
            "-of",
            "csv=p=0",
            input_video,
        ]
        result = subprocess.run(probe_cmd, capture_output=True, text=True)
        if result.returncode == 0 and result.stdout.strip():
            duration = float(result.stdout.strip())
            print(f"è§†é¢‘æ—¶é•¿: {duration:.2f}ç§’")
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨streamä¿¡æ¯è·å–æ—¶é•¿
            probe_cmd2 = [
                "ffprobe",
                "-v",
                "quiet",
                "-select_streams",
                "v:0",
                "-show_entries",
                "stream=duration",
                "-of",
                "csv=p=0",
                input_video,
            ]
            result2 = subprocess.run(probe_cmd2, capture_output=True, text=True)
            if (
                result2.returncode == 0
                and result2.stdout.strip()
                and result2.stdout.strip() != "N/A"
            ):
                duration = float(result2.stdout.strip())
                print(f"è§†é¢‘æ—¶é•¿: {duration:.2f}ç§’")
            else:
                print("æ— æ³•è·å–è§†é¢‘æ—¶é•¿ï¼Œä½¿ç”¨é»˜è®¤é—´éš”æå–")
                duration = None
    except Exception as e:
        print(f"è·å–è§†é¢‘æ—¶é•¿å¤±è´¥: {e}")
        duration = None

    if duration:
        # æ ¹æ®è§†é¢‘æ—¶é•¿å‡åŒ€åˆ†å¸ƒæå–å¸§çš„æ—¶é—´ç‚¹
        # åœ¨è§†é¢‘çš„5%åˆ°95%ä¹‹é—´å‡åŒ€åˆ†å¸ƒï¼Œé¿å…å¼€å¤´ç»“å°¾çš„é»‘å±
        start_time = duration * 0.05
        end_time = duration * 0.95
        time_span = end_time - start_time

        # ç”Ÿæˆå‡åŒ€åˆ†å¸ƒçš„æ—¶é—´ç‚¹
        time_points = []
        for i in range(num_frames):
            if num_frames == 1:
                time_point = duration / 2  # å¦‚æœåªè¦1å¸§ï¼Œå–ä¸­é—´
            else:
                time_point = start_time + (time_span * i / (num_frames - 1))
            time_points.append(time_point)

        print(f"åœ¨ä»¥ä¸‹æ—¶é—´ç‚¹æå–å¸§: {[f'{t:.2f}s' for t in time_points]}")
        print(f"ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œæå–...")

        # åˆ›å»ºçº¿ç¨‹é”ç”¨äºå®‰å…¨æ‰“å°
        print_lock = Lock()

        # å‡†å¤‡å¤šçº¿ç¨‹å‚æ•°
        thread_args = [
            (input_video, output_folder, time_point, i, print_lock)
            for i, time_point in enumerate(time_points)
        ]

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæå–å¸§
        success_count = 0
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            results = list(executor.map(extract_single_frame, thread_args))
            success_count = sum(results)

        print(f"å¤šçº¿ç¨‹æå–å®Œæˆï¼ŒæˆåŠŸæå– {success_count}/{num_frames} å¸§")

        if success_count == 0:
            print("æ‰€æœ‰å¸§æå–éƒ½å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ...")
            return extract_frames_fallback(input_video, output_folder, num_frames)

    else:
        # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å¸§å·é—´éš”æå–
        return extract_frames_fallback(input_video, output_folder, num_frames)

    print("å¸§æå–å®Œæˆ")


def extract_frames_fallback(input_video, output_folder, num_frames):
    """å¤‡ç”¨çš„å•çº¿ç¨‹æå–æ–¹æ¡ˆ"""
    print("ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼šæŒ‰å¸§å·é—´éš”æå–")
    cmd = [
        "ffmpeg",
        "-y",
        "-i",
        input_video,
        "-vf",
        f"select='not(mod(n\\,{max(1, 30)}))',scale=-1:720",  # æ¯30å¸§å–ä¸€å¸§
        "-vframes",
        str(num_frames),
        "-vsync",
        "vfr",
        "-q:v",
        "2",
        "-f",
        "image2",
        os.path.join(output_folder, "frame_%03d.jpg"),
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"FFmpegé”™è¯¯: {result.stderr}")
        # æœ€ç®€å•çš„å¤‡ç”¨æ–¹æ¡ˆ
        simple_cmd = [
            "ffmpeg",
            "-y",
            "-i",
            input_video,
            "-vframes",
            str(num_frames),
            "-q:v",
            "2",
            os.path.join(output_folder, "frame_%03d.jpg"),
        ]
        subprocess.run(simple_cmd, capture_output=True, text=True)


def create_collage(input_folder, output_path, grid_size=(4, 4)):
    """å°†æå–çš„å¸§æ‹¼æ¥æˆç½‘æ ¼"""
    # è·å–æ‰€æœ‰æå–çš„å¸§
    frame_files = sorted(
        [f for f in os.listdir(input_folder) if f.startswith("frame_")]
    )

    if not frame_files:
        print("é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°æå–çš„å¸§æ–‡ä»¶")
        return False

    frame_files = frame_files[: grid_size[0] * grid_size[1]]  # ç¡®ä¿ä¸è¶…è¿‡16å¼ 

    # è¯»å–ç¬¬ä¸€å¸§è·å–å°ºå¯¸
    first_frame = cv2.imread(os.path.join(input_folder, frame_files[0]))
    if first_frame is None:
        print(f"é”™è¯¯ï¼šæ— æ³•è¯»å–ç¬¬ä¸€å¸§ {frame_files[0]}")
        return False

    h, w = first_frame.shape[:2]

    # åˆ›å»ºç©ºç™½ç”»å¸ƒ
    collage = np.zeros((h * grid_size[0], w * grid_size[1], 3), dtype=np.uint8)

    # å°†å¸§æ‹¼æ¥åˆ°ç”»å¸ƒä¸Š
    for i, frame_file in enumerate(frame_files):
        row = i // grid_size[1]
        col = i % grid_size[1]
        frame = cv2.imread(os.path.join(input_folder, frame_file))
        if frame is not None:
            collage[row * h : (row + 1) * h, col * w : (col + 1) * w] = frame  # type: ignore

    # ä¿å­˜æ‹¼æ¥å›¾
    success = cv2.imwrite(output_path, collage)
    if success:
        print(f"æ‹¼æ¥å›¾ä¿å­˜åˆ° {output_path}")
        return True
    else:
        print(f"é”™è¯¯ï¼šæ— æ³•ä¿å­˜æ‹¼æ¥å›¾åˆ° {output_path}")
        return False


def download_bilibili_video(
    url,
    max_duration_min=30,
    cookie_file=None,
    preferred_quality=1080,
    save_path="downloads",
):

    os.system(f"you-get {url} -o {save_path}")


def get_path_video(save_path):
    video_files = [
        f for f in os.listdir(save_path) if f.endswith((".mp4", ".mkv", ".avi"))
    ]
    return os.path.join(save_path, video_files[0]) if video_files else None


def find_bilibili_url(text):
    """
    æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦å«æœ‰Bç«™è§†é¢‘é“¾æ¥ï¼Œè¿”å›åŒ¹é…åˆ°çš„é“¾æ¥æˆ–ç©ºå­—ç¬¦ä¸²

    å‚æ•°:
        text (str): è¦æ£€æµ‹çš„æ–‡æœ¬

    è¿”å›:
        str: åŒ¹é…åˆ°çš„Bç«™è§†é¢‘é“¾æ¥ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    # Bç«™è§†é¢‘é“¾æ¥å¯èƒ½çš„å½¢å¼:
    # 1. https://www.bilibili.com/video/BV1xx411c7mh
    # 2. https://b23.tv/av170001
    # 3. https://m.bilibili.com/video/BV1xx411c7mh
    # 4. å¸¦æœ‰åˆ†äº«å‚æ•°çš„å½¢å¼: https://www.bilibili.com/video/BV1xx411c7mh?share_source=copy_web
    # 5. https:\\/\\/b23.tv\\/gl18XI0 (è½¬ä¹‰æ ¼å¼)
    pattern = r"(https?://(www\.|m\.)?bilibili\.com/video/(BV[\w]+)|https?://b23\.tv/[\w]+|https?:\\?/\\?/(www\.|m\.)?bilibili\.com\\?/video\\?/(BV[\w]+)|https?:\\?/\\?/b23\.tv\\?/[\w]+)"

    match = re.search(pattern, text)
    if match:
        url = match.group(0)
        # å¦‚æœæ˜¯è½¬ä¹‰æ ¼å¼ï¼Œéœ€è¦å»é™¤è½¬ä¹‰å­—ç¬¦
        if "\\/" in url:
            url = url.replace("\\/", "/")
        return url
    return ""


from bs4 import BeautifulSoup


def parse_bilibili_video_info(url) -> dict:
    """è§£æBç«™è§†é¢‘é¡µé¢ä¿¡æ¯"""

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    }
    response = requests.get(url, headers=headers, timeout=10)
    if response.status_code != 200:
        return {}
    html_content = response.text
    soup = BeautifulSoup(html_content, "html.parser")

    video_info = {}

    # è·å–æ ‡é¢˜
    title_tag = soup.find("title")
    if title_tag:
        title = title_tag.get_text().replace("_å“”å“©å“”å“©_bilibili", "")
        video_info["title"] = title

    # è·å–æè¿°/ç®€ä»‹
    desc_meta = soup.find("meta", attrs={"name": "description"})
    if desc_meta and "content" in desc_meta.attrs:  # type: ignore
        description = desc_meta.attrs["content"]  # type: ignore
        if description:
            # æå–ç®€ä»‹éƒ¨åˆ†ï¼ˆé€šå¸¸åœ¨ç¬¬ä¸€ä¸ªé€—å·å‰ï¼‰
            if "," in str(description):
                intro = str(description).split(",")[0]
                video_info["description"] = intro
            else:
                video_info["description"] = str(description)

            # ä»æè¿°ä¸­æå–æ’­æ”¾æ•°æ®ï¼ˆæ’­æ”¾é‡ã€ç‚¹èµæ•°ç­‰ï¼‰
            description_full = str(description)

            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å„ç§æ•°æ®
            play_match = re.search(r"è§†é¢‘æ’­æ”¾é‡ (\d+)ã€", description_full)
            if play_match:
                video_info["play_count"] = int(play_match.group(1))

            danmu_match = re.search(r"å¼¹å¹•é‡ (\d+)ã€", description_full)
            if danmu_match:
                video_info["danmu_count"] = int(danmu_match.group(1))

            like_match = re.search(r"ç‚¹èµæ•° (\d+)ã€", description_full)
            if like_match:
                video_info["like_count"] = int(like_match.group(1))

            coin_match = re.search(r"æŠ•ç¡¬å¸æšæ•° (\d+)ã€", description_full)
            if coin_match:
                video_info["coin_count"] = int(coin_match.group(1))

            collect_match = re.search(r"æ”¶è—äººæ•° (\d+)ã€", description_full)
            if collect_match:
                video_info["collect_count"] = int(collect_match.group(1))

            share_match = re.search(r"è½¬å‘äººæ•° (\d+)", description_full)
            if share_match:
                video_info["share_count"] = int(share_match.group(1))

    # è·å–ä½œè€…
    author_meta = soup.find("meta", attrs={"name": "author"})
    if author_meta and "content" in author_meta.attrs:  # type: ignore
        author = author_meta.attrs["content"]  # type: ignore
        if author:
            video_info["author"] = str(author)

    # è·å–ä¸Šä¼ æ—¶é—´
    upload_meta = soup.find("meta", attrs={"itemprop": "uploadDate"})
    if upload_meta and "content" in upload_meta.attrs:  # type: ignore
        upload_date = upload_meta.attrs["content"]  # type: ignore
        if upload_date:
            video_info["upload_date"] = str(upload_date)

    # è·å–å…³é”®è¯
    keywords_meta = soup.find("meta", attrs={"name": "keywords"})
    if keywords_meta and "content" in keywords_meta.attrs:  # type: ignore
        keywords_content = keywords_meta.attrs["content"]  # type: ignore
        if keywords_content:
            keywords = str(keywords_content).split(",")
            video_info["keywords"] = keywords

    # è·å–è§†é¢‘å°é¢å›¾ç‰‡
    image_meta = soup.find("meta", attrs={"itemprop": "image"})
    if image_meta and "content" in image_meta.attrs:  # type: ignore
        thumbnail = image_meta.attrs["content"]  # type: ignore
        if thumbnail:
            video_info["thumbnail"] = str(thumbnail)

    return video_info


def return_video_info_display(video_info):
    return f"ğŸ¬:{video_info.get('title', 'æœªçŸ¥æ ‡é¢˜')}\nğŸ¤:{video_info.get('author', 'æœªçŸ¥ä½œè€…')}\nğŸ“:{video_info.get('description', 'æœªçŸ¥ç®€ä»‹')}\nğŸ“…:{video_info.get('upload_date', 'æœªçŸ¥ä¸Šä¼ æ—¶é—´')}\nğŸ¥: {video_info.get('play_count', 0):,}\nğŸ’¬: {video_info.get('danmu_count', 0):,}\nğŸ‘: {video_info.get('like_count', 0):,}\nğŸª™: {video_info.get('coin_count', 0):,}\nâ­: {video_info.get('collect_count', 0):,}\nğŸ”—: {video_info.get('share_count', 0):,}\n"


headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3",
    "referer": "https://www.bilibili.com",
}


def download_image(args):
    i, url, folder = args
    url = "https:" + url if not url.startswith("https:") else url
    try:
        img_data = requests.get(url, headers=headers).content
        with open(f"{folder}/image_{i}.jpg", "wb") as img_file:
            img_file.write(img_data)
        return f"å›¾ç‰‡ {i} ä¸‹è½½æˆåŠŸ"
    except Exception as e:
        return f"å›¾ç‰‡ {i} ä¸‹è½½å¤±è´¥: {str(e)}"


def get_bvid(url: str):
    import re

    pattern = r"(BV[a-zA-Z0-9]+)"
    match = re.search(pattern, url)
    return match.group(1) if match else None


# print(get_bvid("https://www.bilibili.com/video/BV1ox4y1q7bP"))
import os
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
import time


async def download_stitched_image_async(
    folder: str, bvurl: str, jpeg_quality=85
) -> str:
    """å¼‚æ­¥ç‰ˆæœ¬çš„ download_stitched_image"""
    loop = asyncio.get_event_loop()

    def _download_stitched_image():
        return download_stitched_image(folder, bvurl, jpeg_quality)

    # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥å‡½æ•°
    return await loop.run_in_executor(None, _download_stitched_image)


async def parse_bilibili_video_info_async(url: str) -> dict:
    """å¼‚æ­¥ç‰ˆæœ¬çš„ parse_bilibili_video_info"""
    loop = asyncio.get_event_loop()

    def _parse_bilibili_video_info():
        return parse_bilibili_video_info(url)

    # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥å‡½æ•°
    return await loop.run_in_executor(None, _parse_bilibili_video_info)


def download_stitched_image(folder: str, bvurl: str, jpeg_quality=85) -> str:
    url = f"https://api.bilibili.com/x/player/videoshot?bvid={get_bvid(bvurl)}"
    response = requests.get(url, headers=headers)
    data = response.json()
    image_urls = data.get("data", {}).get("image", [])
    print(f"éœ€è¦ä¸‹è½½ {len(image_urls)} å¼ å›¾ç‰‡")
    os.makedirs(folder, exist_ok=True)
    # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘ä¸‹è½½
    start_time = time.time()
    with ThreadPoolExecutor(max_workers=min(10, len(image_urls))) as executor:
        futures = [
            executor.submit(download_image, (i, url, folder))
            for i, url in enumerate(image_urls)
        ]
        for future in as_completed(futures):
            print(future.result())

    print(f"ä¸‹è½½å®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.2f} ç§’")

    # opencvæ‹¼æ¥å›¾ç‰‡åˆ°ä¸€èµ·,ç„¶ååˆ é™¤åº•éƒ¨çš„é»‘åº•
    import cv2
    import numpy as np

    images = []
    for i in range(len(image_urls)):
        img = cv2.imread(f"{folder}/image_{i}.jpg")
        if img is not None:
            images.append(img)

    if images:
        # æ‹¼æ¥å›¾ç‰‡
        stitched = np.concatenate(images, axis=0)
        # åˆ é™¤æ‰€æœ‰é»‘è¾¹
        # è½¬æ¢ä¸ºç°åº¦å›¾ä»¥ä¾¿æ›´å¥½åœ°æ£€æµ‹é»‘è¾¹
        gray = cv2.cvtColor(stitched, cv2.COLOR_BGR2GRAY)
        # æ‰¾åˆ°éé»‘è‰²åƒç´ çš„ä½ç½®ï¼ˆé˜ˆå€¼è®¾ä¸º10ä»¥å¤„ç†å¯èƒ½çš„å™ªå£°ï¼‰
        coords = cv2.findNonZero((gray > 10).astype(np.uint8))
        if coords is not None:
            # è·å–è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(coords)
            # è£å‰ªå›¾ç‰‡ï¼Œç§»é™¤æ‰€æœ‰é»‘è¾¹
            stitched = stitched[y : y + h, x : x + w]
        # è®¾ç½®JPEGè´¨é‡ä¸º85ï¼ˆ0-100ä¹‹é—´ï¼Œå€¼è¶Šé«˜è´¨é‡è¶Šå¥½ï¼Œæ–‡ä»¶è¶Šå¤§ï¼‰
        encode_params = [cv2.IMWRITE_JPEG_QUALITY, jpeg_quality]
        cv2.imwrite(f"{folder}/stitched.jpg", stitched, encode_params)
        print(f"æ‹¼æ¥å›¾ç‰‡ä¿å­˜åˆ° {folder}/stitched.jpg")
        return f"{folder}/stitched.jpg"
    return ""


class BiliBiliParsingApplication(GroupMessageApplication):
    def __init__(
        self,
    ):
        applicationInfo = ApplicationInfo("BiliBiliè§£æ", "è§£æBiliBiliè§†é¢‘é“¾æ¥")
        super().__init__(applicationInfo, 10, True, ApplicationCostType.NORMAL)

    async def process(self, message: GroupMessageInfo):
        isCardMessage = False
        display_text = ""
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¡ç‰‡æ¶ˆæ¯
        for k in message.rawMessage["message"]:
            try:
                if k["type"] == "json":
                    # qqå¡ç‰‡æ¶ˆæ¯è§£æ
                    now_json = json.loads(k["data"]["data"])
                    if "meta" in now_json:
                        if "detail_1" in now_json["meta"]:
                            if "qqdocurl" in now_json["meta"]["detail_1"]:
                                qqdocurl = now_json["meta"]["detail_1"]["qqdocurl"]
                                r = requests.get(qqdocurl)
                                no_get_params_url = r.url.split("?")[0]
                                logging.info(f"è§£æç»“æœ:{no_get_params_url}")
                                isCardMessage = True
                                break
            except Exception as e:
                logging.info(f"ä¸æ˜¯å¡ç‰‡æ¶ˆæ¯: {e}")
        if not isCardMessage:
            no_get_params_url = find_bilibili_url(f"{message.rawMessage}")
            if "b23" in no_get_params_url:
                r = requests.get(no_get_params_url)
                no_get_params_url = r.url.split("?")[0]
                display_text += f"{no_get_params_url}\n"

        uuid_str = str(uuid.uuid4())
        folder = f"downloads/{uuid_str}"

        # å¹¶å‘æ‰§è¡Œä¸‹è½½å›¾ç‰‡å’Œè§£æè§†é¢‘ä¿¡æ¯
        image_task = download_stitched_image_async(folder, no_get_params_url)
        info_task = parse_bilibili_video_info_async(no_get_params_url)

        # ç­‰å¾…ä¸¤ä¸ªä»»åŠ¡å®Œæˆ
        image_path, parsed_info = await asyncio.gather(image_task, info_task)
        print("å›¾ç‰‡ä¸‹è½½å’Œè§†é¢‘ä¿¡æ¯è§£æå®Œæˆ")
        
        if isCardMessage:
            display_text += f"{no_get_params_url}\n"
        display_text += return_video_info_display(parsed_info)
        if image_path != "":
            if isCardMessage:
                await ReplySayTextImage(
                    message.websocket,
                    message.groupId,
                    message.messageId,
                    display_text,
                    image_path,
                )
            else:
                # å¦‚æœä¸æ˜¯å¡ç‰‡æ¶ˆæ¯ï¼Œç›´æ¥å‘é€å›¾ç‰‡
                await ReplySayTextImage(
                    message.websocket,
                    message.groupId,
                    message.messageId,
                    display_text,
                    image_path,
                )
        else:
            # å›¾ç‰‡è§£æä¸æˆåŠŸ,ç›´æ¥å‘é€æ–‡æœ¬
            await ReplySay(
                message.websocket,
                message.groupId,
                message.messageId,
                display_text,
            )
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil

        try:
            shutil.rmtree(folder)
        except Exception as e:
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        # input_video = download_bilibili_video(
        #     url=no_get_params_url,
        #     max_duration_min=30,
        #     cookie_file="cookie.txt",
        #     preferred_quality=1080,
        #     save_path=f"downloads/{uuid_str}",
        # )
        # output_video = get_path_video(f"downloads/{uuid_str}")
        # if output_video is None:
        #     print("é”™è¯¯ï¼šæœªæ‰¾åˆ°ä¸‹è½½çš„è§†é¢‘æ–‡ä»¶")
        #     return

        # output_folder = f"downloads/{uuid_str}/output"
        # output_collage = f"downloads/{uuid_str}/collage.jpg"

        # # æå–å¸§
        # extract_frames(output_video, output_folder)

        # # æ£€æŸ¥æ˜¯å¦æˆåŠŸæå–äº†å¸§
        # if not os.path.exists(output_folder) or not os.listdir(output_folder):
        #     print("é”™è¯¯ï¼šæ²¡æœ‰æˆåŠŸæå–åˆ°è§†é¢‘å¸§")
        #     return

        # # åˆ›å»ºæ‹¼å›¾
        # success = create_collage(output_folder, output_collage)

        # if success:
        #     if isCardMessage:
        #         await ReplySayTextImage(
        #             message.websocket,
        #             message.groupId,
        #             message.messageId,
        #             display_text,
        #             output_collage,
        #         )
        #     else:
        #         # å¦‚æœä¸æ˜¯å¡ç‰‡æ¶ˆæ¯ï¼Œç›´æ¥å‘é€å›¾ç‰‡
        #         await ReplySayTextImage(
        #             message.websocket,
        #             message.groupId,
        #             message.messageId,
        #             display_text,
        #             output_collage,
        #         )
        # else:
        #     print("åˆ›å»ºæ‹¼æ¥å›¾å¤±è´¥")

    def judge(self, message: GroupMessageInfo) -> bool:
        return LoadGroupSetting("bilibili_parsing", message.groupId, True) and (find_bilibili_url(f"{message.rawMessage}") != "" or HasAllKeyWords(f"{message.rawMessage}", ["QQå°ç¨‹åº", "å“”å“©å“”å“©"]))  # type: ignore
